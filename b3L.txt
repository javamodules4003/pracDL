import os
import numpy as np
import librosa
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization
from tensorflow.keras.utils import to_categorical

# --- CONFIG ---
DATASET_PATH = r"C:\Users\shlok\Downloads\archive (15)\genres"
MAX_PAD_LEN = 130
N_MFCC = 40

# --- FEATURE EXTRACTION ---
def extract_features(file_path, max_pad_len=MAX_PAD_LEN):
    """Extracts MFCC features from an audio file."""
    audio, sr = librosa.load(file_path, duration=30)
    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=N_MFCC)
    # Pad or trim to fixed length
    mfcc = np.pad(mfcc, ((0, 0), (0, max(0, max_pad_len - mfcc.shape[1]))), mode='constant')[:, :max_pad_len]
    return mfcc

# --- LOAD DATA ---
genres = sorted(os.listdir(DATASET_PATH))
X, y = [], []

for genre in genres:
    genre_path = os.path.join(DATASET_PATH, genre)
    if not os.path.isdir(genre_path):
        continue
    print(f"Processing genre: {genre}")
    for file in os.listdir(genre_path):
        file_path = os.path.join(genre_path, file)
        try:
            features = extract_features(file_path)
            X.append(features)
            y.append(genre)
        except Exception as e:
            print(f"Error with file {file_path}: {e}")

X = np.array(X)
X = np.transpose(X, (0, 2, 1))  # Shape: (samples, timesteps, features)

# --- ENCODE LABELS ---
le = LabelEncoder()
y = to_categorical(le.fit_transform(y))

# --- SPLIT DATA ---
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# --- BUILD MODEL ---
model = Sequential([
    LSTM(64, return_sequences=True, input_shape=(X.shape[1], X.shape[2])),
    BatchNormalization(),
    Dropout(0.3),

    LSTM(32, return_sequences=False),
    BatchNormalization(),
    Dropout(0.3),

    Dense(32, activation='relu'),
    Dropout(0.3),

    Dense(y.shape[1], activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# --- TRAIN ---
history = model.fit(
    X_train, y_train,
    epochs=50,
    batch_size=32,
    validation_split=0.2,
    verbose=1
)

# --- EVALUATE ---
loss, acc = model.evaluate(X_test, y_test, verbose=1)
print(f"\nTest Accuracy: {acc * 100:.2f}%")

# --- OPTIONAL: Plot Accuracy/Loss ---
plt.figure(figsize=(10, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train')
plt.plot(history.history['val_accuracy'], label='Validation')
plt.title('Model Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train')
plt.plot(history.history['val_loss'], label='Validation')
plt.title('Model Loss')
plt.legend()
plt.show()
